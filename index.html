<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Welcome</title>
    <link href="style.css" rel="stylesheet">
    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link href="https://fonts.googleapis.com/css2?family=Inconsolata:wght@200&display=swap" rel="stylesheet">
</head>
<body>
    <div class = "page">
        <div class="sidebar">
            <div class="sidebar-title">
                <h1>Andrew Erskine</h1>
                <h2>Neuroscientist</h2>
                <h2>Developer</h2>
                <img src="img/robodoig.jpg" id="profile-pic">
            </div>
            <nav>
                <div class="link-container">
                    <a href="#about-anchor">About</a>
                </div>
                <div class="link-container">
                    <a href="#work-anchor">Work</a>
                </div>
                <div class="link-container">
                    <a href="#education-anchor">Education</a>
                </div>

                <h3></h3>
                <div class="link-container"></div>
                    <a href="#publication-anchor">Publications</a>
                <div class="link-container">
                    <a href="#software-tools-anchor">Software Tools</a>
                </div>
                <div class="link-container">
                    <a href="#game-dev-anchor">Game Development</a>
                </div>
                <h3></h3>
                <div class="link-container">
                    <a href="https://github.com/RoboDoig">GitHub</a>
                </div>
                <div class="link-container">
                    <a href="https://twitter.com/incisrdrew">Twitter</a>
                </div>
                <div class="link-container">
                    <a href="https://www.linkedin.com/in/andrew-erskine-59090920b/">LinkedIn</a>
                </div>
                <div class="link-container">
                    <a href="mailto:erskine94@gmail.com">Email</a>
                </div>
            </nav>
        </div>
        <div class="main">
            <a id="about-anchor">
                <main>
                    <div class="intro">
                        <p class="intro-lead"><b>I am a neuroscientist working on using all-optical methods to understand cortical circuitry and behaviour. I also develop software for neuroscience research, data analysis and games</b></p>
                        <p>Microsurgical methods including microinjection, perfusion, head-fixation, <i>in-vivo</i> electrophysiology and 2-photon preparations</p>
                        <p>Hardware design and prototyping with focus on custom equipment for behavioural neurophysiology. Proficient in 3D modeling (AutoDesk Inventor)</p>
                        <p>Extensive experience with data analysis approaches for neural and behavioural data</p>
                        <p>Experienced programmer with advanced ability in several languages (MATLAB, Python, C#, JavaScript/HTML/CSS)</p>
                    </div>
                    <div class="work">
                        <a id="work-anchor">
                            <h1 class="section-title">WORK</h1>
                            <div class="milestone-box" id="hires-lab">
                            <h2>2018 - Present</h2>
                                <h2>Postdoctoral Scholar - Hires lab, <i>University of Southern California</i></h2>
                            <p></p>
                            <p>Utilising all-optical techniques to investigate neuronal ensemble recruitment in somatosensory cortex.
                                Using 2-photon imaging with spatial-light modulation optogenetics to investigate information propagation across cortical layers, and the effects of ensemble recruitment on tactile perception. <br /><br />

                                Modified DeepLabCut for Google Cloud - allowing for fast, parallel usage on large whisker tracking datasets.
                            </p>
                        </div>
                            <div class="milestone-box" id="schaefer-lab">
                            <h2>2013 - 2018</h2>
                                <h2>PhD Student - Schaefer lab, <i>The Francis Crick Institute / UCL</i></h2>
                            <p></p>
                            <p>Developed an automated, high-throughput mouse behavior system (AutonoMouse)
                                capable of training 20+ mice simultaneously in GNG/2AFC paradigms; as well as the
                                associated control and analysis software.<br /><br />
                                Utilised AutonoMouse in a large-scale study investigating the effect of targeted
                                olfactory bulb (OB) lesions on olfactory discrimination behaviors (Erskine 2019, PLOS ONE) <br /><br />
                                Using a custom-built odor delivery device, in vivo electrophysiology and automated
                                behavior: investigated the role of temporal patterns in odor concentration on
                                detection and coding in the mouse OB (Ackels, T., Erskine, A. Nature, accepted). <br /><br />
                                Produced several software solutions for use in the lab (AutonoMouse, PulseBoy).
                            </p>
                        </div>
                            <div class="milestone-box" id="manc-university">
                            <h2>2012 - 2013</h2>
                                <h2>Master's Project Student - Petersen lab, <i>The University of Manchester</i></h2>
                            <p></p>
                            <p>Developed protocol and experimental rig for head-fixed GNG behavioral training in
                                mice with simultaneous awake in vivo electrophysiology and high-speed recording
                                / tracking of whisker movement. <br /><br />
                                Using this approach, investigated the coding of whisker kinematics in awake mice
                                at the primary afferent level (Campagner et al., 2016; Bale et al., 2015) <br /><br />
                            </p>
                        </div>
                            <div class="milestone-box" id="columbia">
                                <h2>Summer 2012</h2>
                                <h2>Visiting Scholar - Paninski Lab, <i>Columbia University</i></h2>
                                <p></p>
                                <p>Project investigating approaches for decoding limb position from macaque PMd
                                    multi-site recordings for neural prosthetic applications.
                                </p>
                            </div>
                            <div class="milestone-box" id="manc-summer">
                                <h2>Summer 2011</h2>
                                <h2>Summer Placement Student - Petersen Lab, <i>The University of Manchester</i></h2>
                                <p></p>
                                <p>Project investigating encoding of whisker stimulation in rodent somatosensation.
                                    Built and tested a number of encoding models accounting for whisker afferent firing
                                    under white-noise stimulation.
                                </p>
                            </div>
                        </a>
                    </div>
                    <div class="work">
                        <a id="education-anchor">
                            <h1 class="section-title">EDUCATION</h1>
                            <div class="milestone-box" id="cshl">
                                <h2>2019</h2>
                                <h2>Imaging Structure and Function in the Nervous System, <i>Cold Spring Harbour Laboratory</i></h2>
                                <p></p>
                                <p>Intensive training in advanced optical methods with theoretical and practical components. Lectures and practicals on the most cutting-edge techniques including
                                    spatial-light modulation, temporal focusing, light-sheet techniques, acousto-optical deflectors, remote-focusing, SLAP, SCAPE.
                                </p>
                            </div>
                            <div class="milestone-box" id="sysmic">
                                <h2>2015</h2>
                                <h2>SysMIC Course</i></h2>
                                <p></p>
                                <p>Advanced training in practical applications of
                                    mathematics and computing in biology. Final project: MATLAB implementation of
                                    FitzHugh-Nagumo model of single neuron activity.
                                </p>
                            </div>
                            <div class="milestone-box" id="freiburg">
                                <h2>2014</h2>
                                <h2>Analysis and Models in Neurophysiology, <i>Bernstein Center, Freiburg</i></h2>
                                <p></p>
                                <p> Workshop on computational neuroscience methods, with practical sessions for applying to real data
                                </p>
                            </div>
                            <div class="milestone-box" id="PhD">
                                <h2>2013 - 2018</h2>
                                <h2>PhD Neuroscience, <i>The Francis Crick Institute / UCL, London</i></h2>
                                <p></p>
                                <p> PhD thesis: Perception and representation of temporally patterned odour stimuli in the mammalian olfactory bulb
                                </p>
                            </div>
                            <div class="milestone-box" id="mneurosci">
                                <h2>2009 - 2013</h2>
                                <h2>Combined BSc / MSc in Neuroscience - 1st Class Honours, <i>The University of Manchester</i></h2>
                                <p></p>
                                <p>Broad range of taught and practical neuroscience and general biology modules with additional elected courses in mathematics
                                    and statistics. Masters thesis: Representation of whisker kinematic parameters in the trigeminal ganglion of awake, behaving mice
                                </p>
                            </div>
                            <div class="milestone-box" id="eggy">
                                <h2>2005 - 2009</h2>
                                <h2>GCSE and A-level, <i>Egglescliffe Comprehensive School</i></h2>
                                <p></p>
                                <p>11 A*/A grades at GCSE, 4 A grades at A-level
                                </p>
                            </div>
                        </a>
                    </div>
                    <div class="publications">
                        <a id="publication-anchor">
                            <h1 class="section-title">PUBLICATIONS</h1>
                            <div class="publications-box" id="fast-odours" onclick="window.open('https://www.nature.com/articles/s41586-021-03514-2','_blank')">
                                <img src="img/fast-odours.JPG">
                                <h2>Fast odour dynamics are encoded in the olfactory system and guide behaviour</h2>
                                <p><i>Ackels, T.*, <b>Erskine, A.*,</b> Dasgupta, D.*, Cristina, M., Warner, T., Tootoonian, S., Fukunaga, I., Harris, J., Schaefer, A. T. (Nature, 2021)</i></p>
                                <p>In this project we investigated whether the turbulent dynamics of naturally occurring odours were a useful sensory component of animal behavior.
                                Ultimately we found that mice were able to discriminate correlation structure in odour stimuli at high frequency, suggesting they are capable of using turbulent odour signals for navigation
                                and localisation. We overcame several large technical hurdles to achieve this finding, including development of a new method of measuring different odours simultaneously in the air (defPID); a new
                                olfactometer design capable of extremely precise and fast odour delivery; and integration of these tools into our previously developed automated training platform: AutonoMouse.</p>
                            </div>
                            <div class="publications-box" id="tactile-shape" onclick="window.open('https://www.cell.com/neuron/pdfExtended/S0896-6273(20)30712-1','_blank')">
                                <img src="img/2p.JPG">
                                <h2>Behavioral and Neural Bases of Tactile Shape Discrimination Learning in Head-Fixed Mice</h2>
                                <p><i>Kim, J., <b> Erskine, A., </b> Cheung, J. D., Hires, S. A. (Neuron 2020)</i></p>
                                <p>Using 2-photon imaging and head-fixed behavior, we uncovered how S1 neurons encode tactile shape, and how this encoding shifts over the course of learning.</p>
                            </div>
                            <div class="publications-box" id="autonomouse" onclick="window.open('https://journals.plos.org/plosone/article/comments?id=10.1371/journal.pone.0211571','_blank')">
                                <img src="img/autonomouse.gif">
                                <h2>AutonoMouse: High throughput operant conditioning reveals progressive impairment with graded olfactory bulb lesions</h2>
                                <p><i><b>Erskine, A., </b> Bus, T., Herb, J. T., Schaefer, A. T. (PLOS ONE 2019)</i></p>
                                <p>We developed AutonoMouse to reduce the bottleneck in neuroscience research from manual or semi-manual behavioral training and testing techniques. In AutonoMouse, large
                                 cohorts of mice can be trained simultaneously over long periods with minimal experimenter intervention. Experiments in AutonoMouse can be designed, implemented and monitored remotely with dedicated software.
                                 Using this system, we performed a systematic study of the effect of olfactory bulb disruption on olfactory discrimination, finding that olfactory memory was the most prominently modified behaviour.</p>
                            </div>
                            <div class="publications-box" id="whisker-kinematics" onclick="window.open('https://elifesciences.org/articles/10696','_blank')">
                                <img src="img/whisker.gif">
                                <h2>Prediction of primary somatosensory neuron activity during active tactile exploration</h2>
                                <p><i>Campagner, D., Evans, H. M., Bale, M. R., <b>Erskine, A., </b> Petersen, R. S. (eLife 2016)</i></p>
                                <p>This study used high-speed videography with awake electrophysiology to uncover the kinematic variables encoded by trigeminal afferents in the whisker system.</p>
                            </div>
                            <div class="publications-box" id="whisker-precision" onclick="window.open('https://www.jneurosci.org/content/35/15/5935.abstract','_blank')">
                                <img src="img/whisker-precision.jpg">
                                <h2>Microsecond-scale timing precision in rodent trigeminal primary afferents</h2>
                                <p><i>Bale, M. R., Campagner, D. <b>Erskine, A., </b> Petersen, R. S. (JNeurosci 2015)</i></p>
                                <p>Here we uncovered the extraordinary precision in spike-timing and information capacity of rodent whisker trigeminal afferents.</p>
                            </div>
                        </a>
                    </div>
                    <div class="software-tools">
                        <a id="software-tools-anchor">
                            <h1 class="section-title">SOFTWARE TOOLS</h1>
                            <div class="software-box" id="rnns-neuro" onclick="window.open('https://dev.to/robodoig/a-practical-guide-to-rnns-for-neuroscience-research-in-keras-1ad2','_blank')">
                                <img src="img/rnn.JPG">
                                <h2>A practical guide to RNNs for neuroscience research in Keras</h2>
                                <p>Inspired by COSYNE 2021 - a practical guide for implementing RNN models for neuroscience research, with code examples and explanation.
                                </p>
                            </div>

                            <div class="software-box" id="dlc-cloudml" onclick="window.open('https://github.com/RoboDoig/dlc-cloudml','_blank')">
                                <img src="img/dlc-whiskers.gif">
                                <h2>Cloud-based DeepLabCut</h2>
                                <p>A modification of DeepLabCut that allows the training step to be performed on Google Cloud. Moving this step to the cloud
                                    means that tracking models for multiple datasets can be trained in parallel without multiple local GPUs.
                                </p>
                            </div>

                            <div class="software-box" id="autonomouse-control" onclick="window.open('https://github.com/RoboDoig/autonomouse-control','_blank')">
                                <img src="img/gng.JPG">
                                <h2>AutonoMouse Control</h2>
                                <p>This software controls behavioral experiments for the automated mouse training platform: AutonoMouse. It is a GUI that allows the user
                                to precisely design and implement long-term behavioral experiments with multiple animals simultaneously, with the ability to tailor experimental
                                parameters to individual animals. It also tracks important metrics of mouse behavior during trials.</p>
                            </div>

                            <div class="software-box" id="pulse-boy" onclick="window.open('https://github.com/RoboDoig/PulseBoy','_blank')">
                                <img src="img/PulseBoy.JPG">
                                <h2>PulseBoy</h2>
                                <p>PulseBoy is a GUI tool created to drive solenoid arrays used in olfactometers to be able to generate complex olfactory stimuli in a flexible manner. However,
                                it is also a general tool for creating complex patterns of digital commands across many channels in National Instruments devices. PulseBoy operates on a modular
                                principle, in which each digital channel can be assigned to a particular digital signal production widget with associated variable modifiers. It allows for users to create
                                their own widgets so that almost any digital pattern can be produced. </p>
                            </div>
                        </a>
                    </div>
                    <div class="game-dev">
                        <a id="game-dev-anchor">
                            <h1 class="section-title">GAME DEVELOPMENT</h1>
                            <div class="software-box" id="darkrift-playfab" onclick="window.open('https://dev.to/robodoig/unity-multiplayer-bottom-to-top-46cj','_blank')">
                                <img src="img/DR-Tut.png">
                                <h2>DarkRift + PlayFab</h2>
                                <p>Tutorial on designing, implementing and deploying a multiplayer game with DarkRift and PlayFab</p>
                            </div>
                            <div class="software-box" id="anagrams" onclick="window.open('https://github.com/RoboDoig/anagrams.js','_blank')">
                                <img src="img/anagrams.JPG">
                                <h2>anagrams.js</h2>
                                <p>Multiplayer, browser-based anagrams game. Build with node.js, express and socket.io</p>
                            </div>
                            <div class="game-box">
                                <iframe src="https://itch.io/embed/617246" frameborder="0"><a href="https://robodoig.itch.io/keep-it-alive">Keep "IT" Alive by RoboDoig</a></iframe>
                                <h2>Keep "IT" Alive</h2>
                                <p>A minimalist word game for Ludum Dare 46</p>
                            </div>
                            <div class="game-box">
                                <iframe src="https://itch.io/embed/494780" frameborder="0"><a href="https://robodoig.itch.io/medium-sized-field-simulator-2019">Medium-Sized Field Simulator 2019 by RoboDoig</a></iframe>
                                <h2>Medium-Sized Field Simulator 2019</h2>
                                <p>Something between Conway's Game of Life and a farming simulator, for Ludum Dare 45</p>
                            </div>
                            <div class="software-box" id="goap" onclick="window.open('https://github.com/RoboDoig/goap','_blank')">
                                <img src="img/goap.JPG">
                                <h2>GOAP Experiments</h2>
                                <p>Goal-oriented action planning is a powerful approach for AI in games, but it can be computationally expensive due to large search graphs.
                                    This implementation borrows some methods from another game AI technique - A* pathfinding - to speed up its search time</p>
                            </div>
                        </a>
                    </div>
                </main>
            </a>
        </div>
    </div>
</body>
</html>
